{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torchaudio\n",
    "import torchaudio.transforms as tt\n",
    "import torchaudio.functional as ff\n",
    "import matplotlib.pyplot as plt\n",
    "from torchaudio.utils import download_asset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(r\"C:\\Users\\toviste\\Local_Documents\\Local_Python\\asteroid\")\n",
    "import asteroid.dsp.beamforming as bf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SAMPLE_RATE = 16000\n",
    "SAMPLE_CLEAN = download_asset(\"tutorial-assets/mvdr/clean_speech.wav\")\n",
    "SAMPLE_NOISE = download_asset(\"tutorial-assets/mvdr/noise.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_mixture(waveform_clean, waveform_noise, target_snr):\n",
    "    power_clean_signal = waveform_clean.pow(2).mean()\n",
    "    power_noise_signal = waveform_noise.pow(2).mean()\n",
    "    current_snr = 10 * torch.log10(power_clean_signal / power_noise_signal)\n",
    "    waveform_noise *= 10 ** (-(target_snr - current_snr) / 20)\n",
    "    return waveform_clean + waveform_noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform_clean, sr = torchaudio.load(SAMPLE_CLEAN)\n",
    "waveform_noise, sr2 = torchaudio.load(SAMPLE_NOISE)\n",
    "assert sr == sr2 == SAMPLE_RATE\n",
    "# The mixture waveform is a combination of clean and noise waveforms with a desired SNR.\n",
    "target_snr = 3\n",
    "waveform_mix = generate_mixture(waveform_clean, waveform_noise, target_snr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "waveform_mix = waveform_mix.to(torch.double).unsqueeze(0)\n",
    "waveform_clean = waveform_clean.to(torch.double).unsqueeze(0)\n",
    "waveform_noise = waveform_noise.to(torch.double).unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_FFT = 1024\n",
    "N_HOP = 256\n",
    "stft = tt.Spectrogram(n_fft=N_FFT, hop_length=N_HOP, power=None)\n",
    "istft = tt.InverseSpectrogram(n_fft=N_FFT, hop_length=N_HOP)\n",
    "\n",
    "stft_mix = stft(waveform_mix)\n",
    "stft_clean = stft(waveform_clean)\n",
    "stft_noise = stft(waveform_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "REFERENCE_CHANNEL = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_irms(stft_clean, stft_noise):\n",
    "    mag_clean = stft_clean.abs() ** 2\n",
    "    mag_noise = stft_noise.abs() ** 2\n",
    "    irm_speech = mag_clean / (mag_clean + mag_noise)\n",
    "    irm_noise = mag_noise / (mag_clean + mag_noise)\n",
    "    return irm_speech[:, REFERENCE_CHANNEL, :, :], irm_noise[:, REFERENCE_CHANNEL, :, :]\n",
    "\n",
    "\n",
    "irm_speech, irm_noise = get_irms(stft_clean, stft_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scm_speech = bf.compute_scm(x=stft_mix, mask=irm_speech)\n",
    "scm_noise = bf.compute_scm(x=stft_mix, mask=irm_noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beamformer = bf.RTFMVDRBeamformer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stft_enhanced = beamformer(mix=stft_mix, target_scm=scm_speech, noise_scm=scm_noise, solution='evd')\n",
    "waveform_enhanced = istft(stft_enhanced, length=waveform_mix.shape[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(waveform_clean[0, 0, :4*SAMPLE_RATE])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(waveform_mix[0, 0, :4*SAMPLE_RATE])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "plt.plot(waveform_enhanced[0, :4*SAMPLE_RATE])\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "torchaudio.save(\"enhanced.wav\", waveform_enhanced, sr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".conda",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
